# 3D Localization and Mapping of Ground Vehicle
> Own_co_slam was made as part of the M.Tech project<br />
> Here, co-slam was modified with different mlp layers to make sure that it is outperforming to provide better results. 


### [Thesis](https://github.com/Pallab007Saha/Own_co_slam/blob/master/Results/M22RM218_MTP_Report.pdf) | [3D view](https://github.com/Pallab007Saha/Own_co_slam/blob/master/Results/Our%20Method.ply) | [View shots](https://github.com/Pallab007Saha/Own_co_slam/tree/master/Results)


<p align="center">  
  <a href="">
    <img src="./\Results/\Results.jpg" alt="Logo" width="80%">
  </a>
</p>
Here, you could see the outcome from different angles.

## Skills:
- Python
- PyTorch
- CUDA
- High-Performance Computing (HPC)
- Multi-Layer Perceptron (MLP)
- Activation Functions (SELU, Mish)
- 3D Localization and Mapping
- Object Detection
- Machine Learning (ML)

## Summary:
Engineered and advanced a state-of-the-art MLP-based algorithm for 3D localization and mapping of ground vehicles, integrating SELU and Mish activation functions to achieve a 2-3% improvement in accuracy, completeness, and depth. Leveraged High-Performance Computing (HPC) with PyTorch and CUDA to optimize implementation and testing, significantly enhancing the Co-SLAM model. This innovation not only reduced processing delays but also delivered clearer, more precise 3D mapping, substantially advancing object detection and navigation capabilities crucial for Advanced Driver Assistance Systems (ADAS) applications.




## Installation

Please follow the instructions below to install the repo and dependencies.

```bash
git clone https://github.com/Pallab007Saha/Own_co_slam.git
cd Own_co_slam
```

### Setup environment

```bash
# Create conda environment
conda create -n coslam python
conda activate env

# Install the pytorch
pip install torch torchvision torchaudio

# Install all the dependencies
pip install -r requirements.txt
#might need to check for missing dependencies in case giving error

# Build extension (marching cubes from neuralRGBD)
cd external/NumpyMarchingCubes
python setup.py install

```



## Dataset

#### Replica

Download the sequences of the Replica Dataset generated by the authors of iMAP into `./data/Replica` folder. 

```bash
bash scripts/download_replica.sh # Released by authors of NICE-SLAM
```

#### Synthetic RGB-D dataset

Download the sequences of the synethetic RGB-D dataset generated by the authors of neuralRGBD into `./data/neural_rgbd_data` folder. We exclude the scenes with NaN poses generated by BundleFusion.

```bash
bash scripts/download_rgbd.sh 
```



#### TUM RGB-D

Download 3 sequences of TUM RGB-D dataset into `./data/TUM` folder.

```bash
bash scripts/download_tum.sh 
```



## Run

You can run using the code below:

```
python coslam.py --config './configs/{Dataset}/{scene}.yaml 
```



You can run with multi-processing using the code below:

```
python coslam_mp.py --config './configs/{Dataset}/{scene}.yaml 
```



## Acknowledgement

We adapt codes from some awesome repositories, including [Co-SLAM](https://github.com/HengyiWang/Co-SLAM), [NICE-SLAM](https://github.com/cvg/nice-slam), [NeuralRGBD](https://github.com/dazinovic/neural-rgbd-surface-reconstruction), [tiny-cuda-nn](https://github.com/NVlabs/tiny-cuda-nn). Thanks for making the code available.

